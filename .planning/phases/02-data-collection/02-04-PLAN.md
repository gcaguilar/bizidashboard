---
phase: 02-data-collection
plan: 04
type: execute
wave: 2
depends_on: ["02-02", "02-03"]
files_modified:
  - src/app/api/status/route.ts
  - src/lib/metrics.ts
  - package.json
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Status endpoint shows last successful poll timestamp"
    - "Status endpoint shows total rows collected"
    - "Status endpoint shows validation errors count"
    - "Status endpoint shows data freshness status"
    - "Metrics stored persistently across restarts"
  artifacts:
    - path: "src/app/api/status/route.ts"
      provides: "Observability dashboard API"
      exports: ["GET"]
    - path: "src/lib/metrics.ts"
      provides: "Persistent metrics tracking"
      exports: ["recordCollection", "getMetrics", "incrementValidationErrors"]
  key_links:
    - from: "src/app/api/status/route.ts"
      to: "src/lib/metrics.ts"
      via: "getMetrics"
      pattern: "getMetrics"
    - from: "src/jobs/bizi-collection.ts"
      to: "src/lib/metrics.ts"
      via: "recordCollection"
      pattern: "recordCollection"
    - from: "src/lib/observability.ts"
      to: "src/lib/metrics.ts"
      via: "incrementValidationErrors"
      pattern: "incrementValidationErrors"
---

<objective>
Build observability dashboard endpoint and persistent metrics tracking for the data pipeline.

Purpose: Provides visibility into pipeline health through a status endpoint showing key metrics: last poll time, total records, validation errors, and data freshness. Enables monitoring and alerting.

Output: Working /api/status endpoint displaying real-time pipeline metrics with persistent storage.
</objective>

<execution_context>
@/home/guichu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/guichu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-collection/02-RESEARCH.md

## Prior Plans Context

Plan 02-02 provides:
- validateDataQuality() with Five Pillars checks
- storeStationStatuses() for database operations
- DataObservabilityMetrics interface

Plan 02-03 provides:
- runCollection() that returns CollectionResult
- Job state tracking (lastRun, consecutiveFailures)
- POST /api/collect for manual triggering

## Metrics Requirements (from ROADMAP.md)

INFRA-04: Data observability (freshness alerts, volume checks)

Success Criteria #6: Observability dashboard shows:
- Last successful poll timestamp
- Rows collected (total and recent)
- Validation errors count
- Data freshness status

## Success Criteria from Phase 2

1. Automated polling runs every 30 minutes ✓ (Plan 03)
2. Station data stored for every poll ✓ (Plan 02)
3. Data validation catches stale data, schema changes ✓ (Plan 02)
4. GBFS discovery file parsed dynamically ✓ (Plan 01)
5. Exponential backoff on errors ✓ (Plan 01)
6. Observability dashboard shows metrics ← This plan

## Metrics to Track

Pipeline metrics:
- lastSuccessfulPoll: Date | null
- totalRowsCollected: number
- pollsLast24Hours: number
- validationErrors: number
- consecutiveFailures: number

Data quality metrics:
- lastDataFreshness: boolean
- lastStationCount: number
- averageStationsPerPoll: number

System metrics:
- uptime: Date (when app started)
- version: string (from package.json)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Persistent Metrics Store</name>
  <files>src/lib/metrics.ts</files>
  <action>
    Create src/lib/metrics.ts for persistent metrics tracking across restarts.

    Implementation options (choose one):

    Option A: SQLite/Prisma (Recommended for MVP)
    - Add MetricSnapshot model to prisma/schema.prisma
    - Or use existing tables with aggregation queries
    - Pros: Persistent, integrated with existing DB
    - Cons: Requires schema change

    Option B: File-based JSON
    - Store metrics in data/metrics.json
    - Read/write on each collection
    - Pros: Simple, no schema changes
    - Cons: File I/O on every poll

    Option C: In-memory with periodic persistence
    - Keep metrics in memory
    - Persist to file/DB every N minutes
    - Pros: Fast, simple
    - Cons: Lost on crash

    Recommended: Option A with Prisma
    
    Add to schema.prisma:
    ```prisma
    model CollectionMetrics {
      id                Int      @id @default(autoincrement())
      recordedAt        DateTime
      stationCount      Int
      freshnessMinutes  Float
      hadWarnings       Boolean
      createdAt         DateTime @default(now())
      
      @@index([recordedAt])
    }
    ```

    Or use aggregation queries on existing StationStatus table:
    - lastSuccessfulPoll = max(StationStatus.recordedAt)
    - totalRowsCollected = count(StationStatus)
    - pollsLast24Hours = count distinct recordedAt (rounded to hours)

    Required exports:
    1. recordCollection(result: CollectionResult): Promise<void>
       - Save metrics snapshot after each successful collection
       - Store: recordedAt, stationCount, freshness status, warnings count
    2. getMetrics(): Promise<MetricsSummary>
       - Query aggregations from database
       - Return: lastPoll, totalRows, polls24h, avgStations, etc.
    3. incrementValidationErrors(): void
       - Track validation error count (in-memory or DB)
    4. MetricsSummary interface
       - All the fields needed for status endpoint

    Implementation with existing schema (no changes needed):
    - lastSuccessfulPoll: prisma.stationStatus.aggregate({ max: { recordedAt } })
    - totalRowsCollected: prisma.stationStatus.count()
    - pollsLast24h: count distinct dates from recordedAt
    - recentStationCount: stations from last poll
    - validationErrors: store in separate file or memory
  </action>
  <verify>
    - File src/lib/metrics.ts exists with exports
    - Can record collection metrics
    - Can retrieve metrics summary
    - TypeScript compiles without errors
  </verify>
  <done>
    Metrics module complete with recordCollection and getMetrics functions using existing database schema
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Status API Endpoint</name>
  <files>src/app/api/status/route.ts</files>
  <action>
    Create src/app/api/status/route.ts for the observability dashboard.

    Required exports:
    1. GET handler returning pipeline status
       - Call getMetrics() to get database metrics
       - Call getJobState() to get job state
       - Query recent collections from StationStatus
       - Return JSON with:
         ```json
         {
           "pipeline": {
             "status": "healthy" | "degraded" | "down",
             "lastSuccessfulPoll": "2026-02-05T12:30:00Z",
             "minutesSinceLastPoll": 12,
             "consecutiveFailures": 0,
             "totalPolls": 150
           },
           "data": {
             "totalRowsCollected": 41400,
             "pollsLast24Hours": 48,
             "averageStationsPerPoll": 276,
             "lastStationCount": 276
           },
           "quality": {
             "lastDataFreshness": true,
             "lastFreshnessMinutes": 2.5,
             "validationErrors24h": 0,
             "warnings": []
           },
           "system": {
             "version": "1.0.0",
             "uptime": "2026-02-05T10:00:00Z",
             "environment": "production"
           }
         }
         ```

    2. Status determination logic
       - "healthy": last poll within 35 minutes, no consecutive failures
       - "degraded": last poll within 2 hours, or 1-2 consecutive failures
       - "down": no poll in 2+ hours, or 3+ consecutive failures

    3. Caching headers
       - Cache-Control: no-store (always fresh)
       - Or short cache: max-age=60 (1 minute)

    Implementation notes:
    - Import getMetrics from '@/lib/metrics'
    - Import getJobState from '@/jobs/bizi-collection'
    - Import prisma from '@/lib/prisma'
    - Use Prisma aggregations for efficient counting
    - Calculate minutesSinceLastPoll from Date.now() - lastPoll
    - Format all dates as ISO strings
    - Handle null cases (no data yet)
  </action>
  <verify>
    - File src/app/api/status/route.ts exists
    - GET handler returns status JSON
    - TypeScript compiles without errors
    - Can curl /api/status and get response
  </verify>
  <done>
    Status endpoint complete at GET /api/status with pipeline, data, quality, and system sections
  </done>
</task>

<task type="auto">
  <name>Task 3: Wire Metrics into Collection Pipeline</name>
  <files>src/jobs/bizi-collection.ts, src/lib/observability.ts</files>
  <action>
    Update existing files to wire in metrics tracking.

    Update src/jobs/bizi-collection.ts:
    1. Import recordCollection from '@/lib/metrics'
    2. In runCollection(), after successful validation:
       - Call await recordCollection(result)
       - This persists metrics for the status endpoint
    3. Update CollectionResult to include metricsId if using DB

    Update src/lib/observability.ts:
    1. Import incrementValidationErrors from '@/lib/metrics'
    2. In validateDataQuality(), when schema validation fails:
       - Call incrementValidationErrors()
       - Log the specific error
    3. Or call it from data-validator.ts when validation fails

    Update src/services/data-validator.ts:
    1. Import incrementValidationErrors from '@/lib/metrics'
    2. In validateAndStore(), catch block:
       - Call incrementValidationErrors()
       - Then re-throw error

    Implementation notes:
    - Metrics should be recorded only on successful storage
    - Validation errors tracked separately from runtime errors
    - Don't block collection on metrics recording failure
    - Wrap recordCollection in try/catch with console.warn on failure
  </action>
  <verify>
    - recordCollection called after each successful poll
    - incrementValidationErrors called on validation failures
    - No TypeScript errors in updated files
  </verify>
  <done>
    Metrics wired into pipeline - each collection recorded, validation errors tracked
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. GET /api/status returns current pipeline metrics
2. Status includes: last poll, total rows, validation errors, freshness
3. Status determined (healthy/degraded/down) based on last poll time
4. Metrics persist across application restarts
5. Each successful collection updates metrics
6. Validation errors counted and reported
</verification>

<success_criteria>
- src/lib/metrics.ts exports recordCollection and getMetrics
- src/app/api/status/route.ts returns pipeline status JSON
- Status endpoint shows: lastSuccessfulPoll, totalRowsCollected, validationErrors
- Health status calculated from last poll time and failures
- Metrics updated automatically after each collection
- All files compile with TypeScript
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-collection/02-04-SUMMARY.md`
</output>
