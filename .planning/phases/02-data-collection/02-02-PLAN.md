---
phase: 02-data-collection
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/services/data-storage.ts
  - src/lib/observability.ts
  - src/services/data-validator.ts
autonomous: true

must_haves:
  truths:
    - "Station status records stored in database with UTC timestamps"
    - "Data freshness checked (>10 min old flagged as stale)"
    - "Volume anomalies detected (station count outside 200-500 range)"
    - "Schema validation errors logged and tracked"
    - "Observability metrics recorded for each collection"
  artifacts:
    - path: "src/services/data-storage.ts"
      provides: "Database operations for station status"
      exports: ["storeStationStatuses", "getStationCount"]
    - path: "src/lib/observability.ts"
      provides: "Five Pillars data observability checks"
      exports: ["validateDataQuality", "DataObservabilityMetrics"]
    - path: "src/services/data-validator.ts"
      provides: "Data validation orchestration"
      exports: ["validateAndStore"]
  key_links:
    - from: "src/services/data-validator.ts"
      to: "src/lib/observability.ts"
      via: "quality checks"
      pattern: "validateDataQuality"
    - from: "src/services/data-validator.ts"
      to: "src/services/data-storage.ts"
      via: "database storage"
      pattern: "storeStationStatuses|prisma.stationStatus.create"
    - from: "src/lib/observability.ts"
      to: "prisma/schema"
      via: "previous count query"
      pattern: "prisma.stationStatus.count"
---

<objective>
Build data validation and storage layer implementing the Five Pillars of Data Observability.

Purpose: Validates incoming GBFS data for quality (freshness, volume, schema, distribution, lineage) before storage. Stores validated data with proper UTC timestamps. Provides observability metrics for monitoring pipeline health.

Output: Complete data validation pipeline and storage service with quality checks and metrics tracking.
</objective>

<execution_context>
@/home/guichu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/guichu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-collection/02-RESEARCH.md
@prisma/schema.prisma

## Database Schema (from Phase 1)

```prisma
model Station {
  id        String   @id
  name      String
  lat       Float
  lon       Float
  capacity  Int
  isActive  Boolean  @default(true)
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt
  statuses  StationStatus[]
}

model StationStatus {
  id              Int      @id @default(autoincrement())
  stationId       String
  bikesAvailable  Int
  anchorsFree     Int
  recordedAt      DateTime // UTC timestamp from Bizi API
  createdAt       DateTime @default(now()) // When we recorded it
  station         Station  @relation(fields: [stationId], references: [id])
  @@index([stationId, recordedAt])
  @@index([recordedAt])
}
```

## Five Pillars of Data Observability

1. **Freshness**: Data is recent (last_updated within 5 minutes)
2. **Volume**: Expected number of records (~276 stations)
3. **Schema**: Structure matches expected (validated by Zod)
4. **Distribution**: Values are in expected ranges (bikes >= 0, docks >= 0)
5. **Lineage**: Source is traceable (GBFS version logged)

## GBFS Data Mapping

GBFS field → Database field:
- station_id → stationId
- num_bikes_available → bikesAvailable
- num_docks_available → anchorsFree
- last_reported → recordedAt (converted to Date, stored as UTC)

## Data Quality Thresholds (from RESEARCH.md)

- Freshness: maxAge = 300 seconds (5 minutes per GBFS spec)
- Volume: expected 200-500 stations (Bizi has ~276)
- Distribution: bikes >= 0, docks >= 0
- Schema: Validated by Zod (if parsing succeeds, schema is valid)
- Lineage: Check GBFS version starts with "2."
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Data Storage Service</name>
  <files>src/services/data-storage.ts</files>
  <action>
    Create src/services/data-storage.ts for database operations.

    Required exports:
    1. storeStationStatuses(stations: StationStatus[], recordedAt: Date): Promise<StorageResult>
       - Takes array of validated GBFS station status objects
       - recordedAt is the GBFS last_updated converted to Date (UTC)
       - For each station:
         * Check if Station exists in database (by stationId)
         * If not exists, upsert Station with basic info (id, placeholder name)
         * Create StationStatus record with:
           - stationId: station.station_id
           - bikesAvailable: station.num_bikes_available
           - anchorsFree: station.num_docks_available
           - recordedAt: the provided recordedAt Date (UTC)
       - Return StorageResult with:
         * count: number of records stored
         * stationIds: array of station IDs processed
         * timestamp: when storage completed
       - Use Prisma transaction for atomicity
       - Log progress ("Stored status for N stations")

    2. getStationCount(since?: Date): Promise<number>
       - Count total StationStatus records
       - If since provided, count only records with recordedAt >= since
       - Used for observability metrics

    3. getLastCollectionTime(): Promise<Date | null>
       - Get the most recent recordedAt timestamp from StationStatus
       - Return null if no records exist
       - Used to calculate freshness relative to last successful collection

    Types to define:
    - StorageResult: { count: number; stationIds: string[]; timestamp: Date }
    - Use Prisma's StationStatus type from @prisma/client

    Implementation notes:
    - Import prisma from '@/lib/prisma' (or create this import path)
    - Handle case where Station doesn't exist (create stub with just ID)
    - Full station metadata (name, location) populated later from station_information feed
    - Use Promise.all for parallel status creation within transaction
    - All timestamps stored as UTC (Prisma handles this automatically)
  </action>
  <verify>
    - File src/services/data-storage.ts exists with all exports
    - TypeScript compiles without errors
    - Can import StorageResult type
    - Functions have proper Prisma types
  </verify>
  <done>
    Data storage service complete with storeStationStatuses, getStationCount, and getLastCollectionTime functions
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Data Observability Layer</name>
  <files>src/lib/observability.ts</files>
  <action>
    Create src/lib/observability.ts implementing the Five Pillars of Data Observability.

    Required exports:
    1. DataObservabilityMetrics interface
       - freshness: boolean (data is recent)
       - volume: boolean (expected station count)
       - schema: boolean (structure valid)
       - distribution: boolean (values in range)
       - lineage: boolean (source traceable)
       - details: object with:
         * freshnessMinutes: number (age in minutes)
         * stationCount: number
         * expectedRange: { min: number; max: number }
         * gbfsVersion: string

    2. validateDataQuality(data: GBFSResponse, previousCount?: number): DataObservabilityMetrics
       - Freshness check: (now - last_updated) < 300 seconds (5 min)
       - Volume check: station count between 200 and 500
       - Schema check: always true (Zod already validated)
       - Distribution check: all stations have bikes >= 0 and docks >= 0
       - Lineage check: version starts with "2." (GBFS v2.x)
       - Calculate freshnessMinutes from (now - last_updated) / 60
       - Log warnings for any failed checks with details
       - Return complete metrics object

    3. ObservabilityEvent type and logObservabilityEvent function
       - Event type: 'collection_start' | 'collection_success' | 'collection_error' | 'quality_check'
       - Log to console with structured format (JSON-like)
       - Include timestamp, event type, and relevant metrics
       - This creates audit trail for debugging

    4. shouldAlert(metrics: DataObservabilityMetrics): boolean
       - Return true if freshness or volume checks fail
       - These are critical issues requiring attention

    Constants:
    - MAX_AGE_SECONDS = 300 (5 minutes)
    - EXPECTED_STATIONS_MIN = 200
    - EXPECTED_STATIONS_MAX = 500

    Implementation notes:
    - Import GBFSResponse type from '@/schemas/gbfs'
    - Use Date.now() / 1000 for current time in seconds
    - GBFS last_updated is in seconds
    - Log format: "[Observability] Check: freshness=false, age=12.5min"
    - All boolean checks should have detailed logging on failure
  </action>
  <verify>
    - File src/lib/observability.ts exists with all exports
    - DataObservabilityMetrics interface defined
    - validateDataQuality function returns all 5 pillar checks
    - TypeScript compiles without errors
  </verify>
  <done>
    Observability layer complete with Five Pillars validation and structured logging
  </done>
</task>

<task type="auto">
  <name>Task 3: Create Data Validator Orchestrator</name>
  <files>src/services/data-validator.ts</files>
  <action>
    Create src/services/data-validator.ts that orchestrates validation, quality checks, and storage.

    Required exports:
    1. validateAndStore(data: GBFSResponse): Promise<ValidationResult>
       - Orchestrates the complete data processing pipeline:
         a. Run quality checks via validateDataQuality (from observability.ts)
         b. Log observability event for quality check
         c. Convert GBFS timestamps to Date objects (UTC)
            * recordedAt = new Date(data.last_updated * 1000)
         d. Call storeStationStatuses with stations and recordedAt
         e. Log observability event for successful storage
         f. Return ValidationResult with:
            * success: boolean
            * stationCount: number
            * recordedAt: Date
            * quality: DataObservabilityMetrics
            * warnings: string[] (any quality issues)
       - If any step fails:
         * Catch error
         * Log observability event for error
         * Return ValidationResult with success=false and error message
         * Re-throw error for upstream handling

    2. ValidationResult interface
       - success: boolean
       - stationCount: number
       - recordedAt: Date | null
       - quality: DataObservabilityMetrics | null
       - warnings: string[]
       - error?: string

    3. ValidationOptions interface (for future extensibility)
       - skipQualityChecks?: boolean (for recovery scenarios)
       - dryRun?: boolean (validate without storing)

    Implementation notes:
    - Import GBFSResponse from '@/schemas/gbfs'
    - Import validateDataQuality, logObservabilityEvent from '@/lib/observability'
    - Import storeStationStatuses from './data-storage'
    - GBFS last_updated is Unix seconds → multiply by 1000 for JS Date
    - Collect warnings from quality checks (freshness=false, etc.)
    - Transaction: if storage fails, don't report success even if validation passed
    - Log summary at end: "Validated and stored N stations with X warnings"
  </action>
  <verify>
    - File src/services/data-validator.ts exists with exports
    - validateAndStore function orchestrates full pipeline
    - ValidationResult type exported
    - TypeScript compiles without errors
  </verify>
  <done>
    Data validator orchestrator complete, connecting observability checks to storage with proper error handling
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Data storage can save station statuses with UTC timestamps
2. Observability layer checks all Five Pillars (freshness, volume, schema, distribution, lineage)
3. Validator orchestrates validation → quality check → storage pipeline
4. Metrics include freshness age, station count, GBFS version
5. Warnings collected for any quality issues
6. All operations logged for observability
</verification>

<success_criteria>
- src/services/data-storage.ts can store station statuses in Prisma
- src/lib/observability.ts implements all Five Pillars checks
- src/services/data-validator.ts orchestrates the pipeline
- GBFS timestamps correctly converted to UTC Date objects
- Quality issues logged as warnings but don't block storage
- All files compile with TypeScript
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-collection/02-02-SUMMARY.md`
</output>
