---
phase: 03-analytics-engine-aggregation
plan: 02
type: execute
wave: 2
depends_on: [03-01]
files_modified:
  - src/analytics/watermarks.ts
  - src/analytics/job-lock.ts
  - src/analytics/queries/hourly.ts
  - src/analytics/queries/daily.ts
  - src/analytics/retention.ts
  - src/jobs/analytics-aggregation.ts
  - src/lib/jobs.ts
autonomous: true

must_haves:
  truths:
    - "Hourly and daily rollups can be generated incrementally without reprocessing prior data"
    - "Retention cleanup prunes raw and hourly data per policy with safe vacuum handling"
    - "Analytics cron runs on schedule without overlapping executions"
  artifacts:
    - path: "src/analytics/watermarks.ts"
      provides: "Watermark read/write helpers for incremental aggregation"
    - path: "src/analytics/queries/hourly.ts"
      provides: "Hourly rollup query with UPSERT"
    - path: "src/analytics/queries/daily.ts"
      provides: "Daily rollup query with UPSERT"
    - path: "src/analytics/retention.ts"
      provides: "Retention and vacuum routines"
    - path: "src/jobs/analytics-aggregation.ts"
      provides: "Cron job orchestrating rollups and retention"
  key_links:
    - from: "src/jobs/analytics-aggregation.ts"
      to: "src/analytics/queries/hourly.ts"
      via: "runHourlyRollup"
      pattern: "runHourlyRollup"
    - from: "src/jobs/analytics-aggregation.ts"
      to: "src/analytics/retention.ts"
      via: "runRetentionCleanup"
      pattern: "runRetentionCleanup"
    - from: "src/analytics/queries/hourly.ts"
      to: "HourlyStationStat"
      via: "UPSERT"
      pattern: "INSERT INTO HourlyStationStat"
---

<objective>
Implement incremental hourly/daily rollups, retention cleanup, and a cron runner to keep aggregates fresh.

Purpose: Materialize fast analytics tables and enforce the retention ladder without raw table scans.
Output: Rollup query modules, retention routines, and analytics cron job wired into job bootstrap.
</objective>

<execution_context>
@/home/guichu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/guichu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-analytics-engine-aggregation/03-RESEARCH.md
@docs/retention-ladder.md
@src/jobs/bizi-collection.ts
@src/lib/jobs.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add watermarks and hourly/daily rollup queries</name>
  <files>src/analytics/watermarks.ts, src/analytics/queries/hourly.ts, src/analytics/queries/daily.ts</files>
  <action>
Create watermark helpers that:
- getWatermark(name, defaultDate) and setWatermark(name, date)
- store timestamps in AnalyticsWatermark with updatedAt
- use strict "recordedAt > watermark" bounds to avoid double-counting

Implement hourly and daily rollup queries using prisma.$queryRaw with SQLite date functions:
- Hourly: bucket with strftime('%Y-%m-%d %H:00:00', recordedAt)
- Daily: bucket with strftime('%Y-%m-%d 00:00:00', recordedAt)
- Join Station for capacity to compute occupancyAvg (bikesAvailable / capacity)
- Aggregate bikes/anchors min/max/avg and sampleCount
- UPSERT into HourlyStationStat and DailyStationStat on composite keys

Rollups must accept a cutoff timestamp (last complete hour/day) and only process data <= cutoff.
Return counts for rows processed and rows upserted for logging.
  </action>
  <verify>npm run lint</verify>
  <done>Hourly/daily rollup helpers exist with watermark-based incremental bounds and UPSERT logic.</done>
</task>

<task type="auto">
  <name>Task 2: Implement retention cleanup and vacuum routines</name>
  <files>src/analytics/retention.ts</files>
  <action>
Create a retention module that:
- Deletes StationStatus rows older than 30 days (raw retention)
- Deletes HourlyStationStat rows older than 1 year
- Leaves DailyStationStat intact (forever retention)
- Optionally prunes StationAlert rows older than 14 days to keep alert table small

Add a runVacuumIfDue helper that:
- Uses AnalyticsWatermark (name: 'vacuum') to run VACUUM at most once per week
- Runs VACUUM outside critical rollup paths (called only on daily runs)
Log deletion counts and vacuum execution for observability.
  </action>
  <verify>npm run lint</verify>
  <done>Retention cleanup enforces the ladder and VACUUM is throttled to weekly runs.</done>
</task>

<task type="auto">
  <name>Task 3: Add analytics cron job with overlap protection</name>
  <files>src/analytics/job-lock.ts, src/jobs/analytics-aggregation.ts, src/lib/jobs.ts</files>
  <action>
Implement a DB-backed job lock helper that:
- Uses JobLock table with name, lockedAt, lockExpiresAt, lockedBy
- Acquires lock only if expired or missing, and refreshes during run
- Releases lock on completion (or relies on expiry for crash recovery)

Create analytics-aggregation job that:
- Schedules hourly rollups at minute 10 using timezone 'UTC'
- Runs daily rollups and retention after the hourly rollup when a new UTC day completes
- Uses ANALYTICS_WINDOWS delays to avoid partial buckets (e.g., last complete hour/day)
- Logs processed counts and durations

Update src/lib/jobs.ts to start/stop analytics job alongside collection job.
  </action>
  <verify>npm run lint</verify>
  <done>Analytics cron job runs rollups safely without overlapping executions and is wired into job initialization.</done>
</task>

</tasks>

<verification>
Lint passes and analytics cron job compiles with node-cron typings.
</verification>

<success_criteria>
- Hourly and daily aggregates can be recomputed incrementally using watermarks.
- Retention cleanup deletes expired data and VACUUM runs no more than weekly.
- Analytics cron job is registered and protected from overlapping runs.
</success_criteria>

<output>
After completion, create `.planning/phases/03-analytics-engine-aggregation/03-02-SUMMARY.md`
</output>
